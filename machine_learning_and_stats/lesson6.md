---
marp: true
---

<!-- footer: "機械学習（と統計）第6回" -->

# 機械学習

## 第6回: 自信のなさの見積もりとベイズ推論

千葉工業大学 上田 隆一

<br />

<span style="font-size:70%">This work is licensed under a </span>[<span style="font-size:70%">Creative Commons Attribution-ShareAlike 4.0 International License</span>](https://creativecommons.org/licenses/by-sa/4.0/).
![](https://i.creativecommons.org/l/by-sa/4.0/88x31.png)

---

<!-- paginate: true -->

## 今日やること

- 実験結果のベイズ的な考え方
- 共役

---

### ベータ分布（再掲）

- 式: $p(x) = \dfrac{ x^{\alpha-1}(1-x)^{\beta-1}}{B(\alpha,\beta)} = \eta x^{\alpha-1}(1-x)^{\beta-1}$
    - $B$はベータ関数というややこしい関数
- コインの表、裏がそれぞれ$(\alpha-1)$、$(\beta-1)$回出たときに、表が出る確率の分布
    - 投げるほど分布が尖っていく
        - 数学的な解釈: ある確率に収束していく
        - 生物的な解釈: <span style="color:red">ある確率なのではないかとだんだん確信していく</span>


<center>今日はこれを掘り下げます</center>

![bg right:30% 90%](./figs/beta.png)

---

### 問題

- 題材: ボールを投げて頭上の籠に入れる玉入れロボットを作りました。これから実験で籠に入る確率を求めます。
    <br />
- 最初の問題: まず1回試行したら成功しました。成功率はどれだけでしょうか?
    - 話し合ってみましょう
    - 必要な前提をおいて計算してみましょう

---

### 最初の1回の計算方法

- まず、成功率を$t$としましょう
- 試行前、偏見がなければ$t$の分布（確率$t$の密度）はこうなる
    - $p(t) = 1$（注意: 確率が$1$なのではなく、密度が$1$で積分すると$1$になる）
- ベイズの定理のために尤度を考える
    - $\text{Pr}($成功$|t) = t$、$\text{Pr}($失敗$|t) = 1-t$
- ベイズの定理
    - $p(t|$成功$) = \eta\text{Pr}($成功$|t)p(t)=\eta t=2t$

![bg right:35% 100%](./figs/experiment_1.png)

---

### 最初の1回のポイント

- 成功したんだから成功率が$0$ということはない
- 最初成功したからといって次に成功するとは限らない
    - ただし、今の時点では次も成功する可能性は高い

<br />
<br />

<center style="color:red">グラフがこれらのことを示している</center>

![bg right:35% 100%](./figs/experiment_1.png)

---

### 次の問題

- 続けて試行したらまた成功しました。確率分布はどうなるでしょうか？
- 現在の分布: 
    - $p(t|$成功$) = \eta\text{Pr}($成功$|t)p(t)=\eta t=2t$
- 求めたい分布: 
    - $p(t|$成功, 成功$)$
- 尤度
    - $\text{Pr}($成功$|t) = t$、$\text{Pr}($失敗$|t) = 1-t$

---

### 答え

- ベイズの定理を使う
    - $p(t|$成功, 成功$) = \eta\text{Pr}($成功$|t)p(t|$成功$)$
    $=\eta t2t = 2\eta t^2 = 3t^2$
- グラフから
    - $1$に近い成功率の可能性がより高まる
    - $0$に近い成功率の可能性も残っている
- 問題: 成功率$0.5$以下の確率は?
    * $\int_0^{1/2} 3t^2 dt = [t^3]_0^{1/2} = 1/8$

![bg right:35% 100%](./figs/experiment_2.png)

---

### さらに


- 3回目、4回目の試行が失敗でした。
成功率の分布は?
- 求めたい分布: $p(t|$成功, 成功, 失敗, 失敗$)$
- 尤度: $\text{Pr}($失敗$|t) = 1-t$
- 答え（定数は$\eta$に吸収）
    * $p(t|$成功, 成功, 失敗$)$
    $=\eta\text{Pr}($失敗$|t)p(t|$成功, 成功$)$
    $=\eta t^2(1-t)$（上図）
    * $p(t|$成功, 成功, 失敗, 失敗$)$
    $=\eta\text{Pr}($失敗$|t)p(t|$成功, 成功, 失敗$)$
    $=\eta t^2(1-t)^2$（下図）

![bg right:35% 100%](./figs/experiment_3_4.png)

---

### 結局

- $n$回成功、$m$回失敗の場合の成功率の分布: 
    - $p(t|$成功$n$回, 失敗$m$回$) = \eta t^n(1-t)^m$
    - ↑ベータ分布
    - $n, m$が増えていくとだんだん分布が尖って動かなくなってくる（余裕があれば計算してみましょう）
- 重要なこと
    - 試行から単純に計算した成功率は$n/(n+m)$だが、「真の」成功率は確定せず、分布となる
    - ある程度実験しないと確からしい成功率は得られない

![bg right:30% 90%](./figs/beta.png)

---

### ベイズの定理から分かる日常の教訓

（繰り返しになるけど）人間の頭がベイズの定理を厳密に解いているかは分からないが、ベイズの定理を超えて真実を知ることがは原理的に不可能なので・・・

- 何かが1、2回起こったことで、次どうなるかを決めつけてはいけない
    - 日常的にやってませんか?
- 試行を重ねると判断が正しくなっていく
    - 年寄りの話しは基本よく聞いたほうがいい
    - が、しかし、頑固になってしまっているので、途中でルールが変わってしまったことに気付かないと年寄りは間違えたことを言うようになる

---

### ベイズの定理と機械学習

- いまやった分布の更新は、機械学習の基本的な原理
    - 知識が入るごとに何かの分布が変化して尖っていく
    - 知識が入るまえは平たい分布
- 確率の確率分布を考える
    - 「成功率」とは確率なので「確率の確率分布」を考えていたことに
        - 混乱しやすいので分からなくなったら頭の整理が必要


---

## 共役

---

### ベイズの定理の事前・事後確率

- ベイズの定理の計算は事前確率$p(x)$と事後確率$(x|y)$が同じ分布だと簡単
    - ベイズの定理: $p(x|y) = \eta p(y|x)p(x)$
    - 前半の例は両方ベータ分布だった
        - 知識が入ったら$m$と$n$の値だけを更新すればよい（すごく簡単）
- 同じにならないときがある
    - 尤度$p(y|x)$の形による

---

### 事前・事後確率が同じになる組み合わせ（一部）

|$x$の分布（事前・事後分布）|$y$の分布（尤度のもとになる分布）|
|:---:|:---:|
|ベータ分布|ベルヌーイ分布|
|ガウス分布|ガウス-ガンマ分布|
|多次元ガウス分布|ガウス-ウィシャート分布|
|ディリクレ分布|多項分布|
|ガンマ分布|ポアソン分布|

- 分布について
    - ベルヌーイ分布: 前半で扱ったコインの裏表の確率を表す単純な分布
    - 他の分布については各自調査を
- 現象の性質が自然に上記表に当てはまることもあるが、便宜的に使うこともある

---

## （続きがありますが）まとめ

- 確率の確率を考えた
    - 確率や統計値そのものが不確定ということまで考慮しないと、いろいろ議論がおかしなことになる
        - 数回実験しただけで「成功した」と主張するとか
- 実際のところ、実験での証明には不確かさが残る
    - 「AよりBのほうが1%性能がよい」を
    調べるには膨大な回数の実験が必要
        - 実は研究の世界ではそこまで考えられてなくて、
        p値という謎数値で「証明」とする慣行が残存
- その計算方法を考えた
    - ベイズの定理が主役

---

## 補足: 様々な分布III

---

### ベルヌーイ分布

名前はいかついが最も単純な分布

- 確率変数が2値の分布
    - 例: ある重さの偏ったコインがあって、表・裏の出る確率がそれぞれ1/3、2/3
    - 横軸の0: 表、1: 裏

![bg right:20% 90%](./figs/bernoulli.png)

---

### ベルヌーイ分布とベータ分布の関係

- ベータ分布から確率を選ぶとベルヌーイ分布になる
- ベルヌーイ分布状の尤度関数を入力するとベータ分布が変形する

![w:400](./figs/experiment_3.png)$\quad\leftrightarrow\quad$![w:200](./figs/bernoulli.png)

---

### ディリクレ分布

- ベータ分布を裏表から多値に拡張
    - 多値: ここではさいころの目のように確率変数が3値以上をとるもの
    - さいころの出目の確率の確率
        - ディリクレ分布からさいころが製造されるイメージ
- 分布の式
    - $\text{Dir}(\pi_{1:n} | \alpha_{1:n}) = \eta \pi_1^{\alpha_1-1}\pi_2^{\alpha_2-1}\dots\pi_n^{\alpha_n-1} = \eta \prod_{j=1}^n \pi_j^{\alpha_j - 1}$
        - $\pi_{1:n} = (\pi_1, \pi_2, \dots, \pi_n)$: とりうる$n$種類の値が出る確率（足すと1）
        - $\alpha_{1:n}$: ベータ分布の$\alpha, \beta$に相当
            - $n=2$だとベータ分布に（導出してみましょう。解答: 次ページ）
- 図はWikipediaでも見てください
    - ベータ分布を立体化したような形状

---

### ディリクレ分布からベータ分布への変換

- $n=2$なのでこうなる
    - $p(\pi_{1:2} | \alpha_{1:2}) = \eta \pi_1^{\alpha_1-1}\pi_2^{\alpha_2-1}$
- $\pi_1 + \pi_2 = 1$なので、
    - $p(\pi_{1}, \pi_{2} | \alpha_{1:2}) = \eta \pi_1^{\alpha_1-1}(1-\pi_1)^{\alpha_2-1}$
    - $p(\pi_{1}, 1-\pi_{1} | \alpha_{1:2}) = \eta \pi_1^{\alpha_1-1}(1-\pi_1)^{\alpha_2-1}$
- 「$\pi_1$と$1-\pi_1$」の分布というのはつまり$\pi_1$の分布なので
    - $p(\pi_{1} | \alpha_{1:2}) = \eta \pi_1^{\alpha_1-1}(1-\pi_1)^{\alpha_2-1}$
- $\pi_1=t$、$\alpha_1 = \alpha$、$\alpha_2 = \beta$とおくと
    - $p(t | \alpha,\beta) = \eta t^{\alpha-1}(1-t)^{\beta-1}$
